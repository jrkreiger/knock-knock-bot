{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T17:08:35.027284Z",
     "start_time": "2020-04-16T17:08:32.872439Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T17:38:35.717963Z",
     "start_time": "2020-04-16T17:38:35.697236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knock, knock. Who’s there? Canoe. Canoe who? C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knock, knock. Who’s there? Merry. Merry who? M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knock, knock. Who’s there? Orange. Orange who?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knock, knock. Who’s there? Anee. Anee,who? Ane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knock, knock. Who’s there? Iva. Iva who? I’ve ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Knock, knock. Who’s there? Canoe. Canoe who? C...\n",
       "1  Knock, knock. Who’s there? Merry. Merry who? M...\n",
       "2  Knock, knock. Who’s there? Orange. Orange who?...\n",
       "3  Knock, knock. Who’s there? Anee. Anee,who? Ane...\n",
       "4  Knock, knock. Who’s there? Iva. Iva who? I’ve ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_csv('knock_knock.csv', header=None)\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T17:49:28.182789Z",
     "start_time": "2020-04-16T17:46:51.750906Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textgenrnn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/60/419daf7e2d87bcafc6f0f65736ce76e5cc83cebbae758dd59b4c1fae99cd/textgenrnn-2.0.0.tar.gz (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in ./anaconda3/lib/python3.7/site-packages (from textgenrnn) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.7/site-packages (from textgenrnn) (0.21.2)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.7/site-packages (from textgenrnn) (4.32.1)\n",
      "Collecting keras (from textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 990kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.1.0 (from textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/a0dbd642e68e68f3e309d1413abdc0a7aa7e1534c79c0fc2501defb864ac/tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8MB)\n",
      "\u001b[K     |████████████████████████████████| 120.8MB 127kB/s eta 0:00:01   |█▉                              | 7.1MB 1.6MB/s eta 0:01:14     |████                            | 14.8MB 1.9MB/s eta 0:00:57\n",
      "\u001b[?25hRequirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from h5py->textgenrnn) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7 in ./anaconda3/lib/python3.7/site-packages (from h5py->textgenrnn) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in ./anaconda3/lib/python3.7/site-packages (from scikit-learn->textgenrnn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/lib/python3.7/site-packages (from scikit-learn->textgenrnn) (0.13.2)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.7/site-packages (from keras->textgenrnn) (5.1.1)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras->textgenrnn)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras->textgenrnn)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 759kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 1.1MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.7MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting protobuf>=3.8.0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/25/c057a298635d08d087a20f51ff4287d821814208ebb045d84ea65535b3e3/protobuf-3.11.3-cp37-cp37m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in ./anaconda3/lib/python3.7/site-packages (from tensorflow>=2.1.0->textgenrnn) (1.11.2)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/05/c7450cec52bb1e3d7c56efd384c0ee647cd2b44946004035b3abe3493407/grpcio-1.28.1-cp37-cp37m-macosx_10_9_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./anaconda3/lib/python3.7/site-packages (from tensorflow>=2.1.0->textgenrnn) (0.33.4)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast==0.2.2 (from tensorflow>=2.1.0->textgenrnn)\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow>=2.1.0->textgenrnn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (41.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2.22.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 942kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (0.15.4)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/97/5e7083a5be4cbd1d928061c9d9cb3c070e55d5a15c563be41cb47b544807/google_auth-1.14.0-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 1.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (3.0.4)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/59/524ffb454d05001e2be74c14745b485681c6ed5f2e625f71d135704c0909/cachetools-4.1.0-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 919kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 1.2MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: textgenrnn, absl-py, termcolor, gast\n",
      "  Building wheel for textgenrnn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jennykreiger/Library/Caches/pip/wheels/d2/a3/54/64254fb9f530c33778cd1d4d57a7a2c2d6aebde97585a85893\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jennykreiger/Library/Caches/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jennykreiger/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jennykreiger/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built textgenrnn absl-py termcolor gast\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.3.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras, absl-py, grpcio, oauthlib, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, markdown, protobuf, tensorboard, opt-einsum, tensorflow-estimator, google-pasta, termcolor, gast, astor, tensorflow, textgenrnn\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.1.0 gast-0.2.2 google-auth-1.14.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.28.1 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.2.1 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 textgenrnn-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T17:50:27.437230Z",
     "start_time": "2020-04-16T17:50:13.288782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Haiku] My friends at this gem was the bill game kicking and the substance of the state of the game of the show whenever you have a new video.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()\n",
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
    "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
    "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
    "    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n",
    "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
    "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
    "}\n",
    "\n",
    "train_cfg = {\n",
    "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
    "    'num_epochs': 20,   # set higher to train the model for longer\n",
    "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
    "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
    "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
    "    'validation': True,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
    "    'is_csv': True   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"knock_knock.csv\"\n",
    "model_name = 'colaboratory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T17:57:42.983776Z",
     "start_time": "2020-04-16T17:53:23.198548Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 texts collected.\n",
      "Training on 4,823 character sequences.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 37 steps\n",
      "Epoch 1/5\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.7769####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\"Knock, knock. Whos there? Alex. Whos there? Imma. A who? Alex who? Alex who? Alex who? Dish who? Impaige who? Adore who? Alex the whos there? Is there? Imma. Whos there? Annie who? Alex who? Alex who? Alex who? Dont knock. Whos there? Is there? Imma. Whos there? Imma. Imma who? Adore who? A the th\n",
      "\n",
      "\"Knock, knock. Whos there? Annie who? Imma who? Alex the who? Abbot who? A little of you remember through the throws or you dont know who? Im who? Alabanent who? A little of you realize that was there? Imma who? Alex through the who? Alex through the whos there? Imma who? Alex who? Alex who? A litt\n",
      "\n",
      "\"Knock, knock. Whos there? Abby who? Ivor who? Althea who? Adore who? Althea who? Alex who? Althea who? Abbot who? Althea who? Abbot and who? Alex who? Althea who? Alex who? Alex who? A large who? Alex compare who? Alex through the whos there? Im who? Abbot who? Alex who? Adore who? Alex the whos t\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\"Knock, knock. Whos there? Iam is between new knoce. Imma who? Its dont there on my dishes who? Imma. Here are my who? Imma. Im who? Imma who? Annie who? Knock, knock. Whos there? Nooh who? Alex who? Just a have you! Annie who? Ivor knock. Whos there? Adore who? Adore who were a who? Ivor who? Iman\n",
      "\n",
      "\"Knock, knock. Whos there? Immoit ape in the doortret.\"\n",
      "\n",
      "\"Knock, knock. Whos there? Knock. Come who? Imma who? A lettuce who? Ben who? Althea who? Adore who? Althea look like there? Iam on disappear. Whos there? A be cow a hard of you realize that are we sadied to go?\"\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\"Knock, knock. Whos there? Lettuce to craw you. Such a who? Harley I almost Ivoud doornes who? Iona tea to VenTA apent a desk. Isabon through welcome!\"\n",
      "\n",
      "\"Knock, knock. Whos there? As you! Whos there? Talk these fell rut \"Knock, knocking. Whos there? Isafpe. Il debt, almost going to be annie a highlight. Whos there? Hibana. Whos there? Justin me. Otto who? NA whos dont do you let me?\"\n",
      "\n",
      "\"Knock, knock. Whos there? DIMO. Hound to Robin finding?\"\n",
      "\n",
      "37/37 [==============================] - 67s 2s/step - loss: 0.7813\n",
      "Epoch 2/5\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.6177####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\"Knock, knock. Whos there? Adore. Althea who? Are you dont know who? Abbot who? Are you a letter to the who?\"\n",
      "\n",
      "\"Knock, knock. Whos there? Annie. Annie who? Althea who? Althea who? Althea who? Althea who? Althea who? Adore who? Althea who? Abbot who? Althea who? Althea who? Althea who? Althea who? Annie police who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who\n",
      "\n",
      "\"Knock, knock. Whos there? Abby who? Althea who? Althea who? Althea who? Althea who? Althea who? Annie who? Althea who? Althea who? Althea who? Althea who? Adore who? Abby through the who? Abby who? Althea who? Abby who? Althea who? Althea who? Althea who? Adore who? Althea who? Althea who? Althea \n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\"Knock, knock. Whos there? Adore. Annie who? Apple who? Robin the whos there? Dozen to come back.\"\n",
      "\n",
      "\"Knock, knock. Whos there? Orange me go banana. Dishes who? A lettuce who? Avenue who? Althea who? Lettuce who? CD who? Abby who? Orange you who? Abbot to meet you who? King Knock Cow you!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Thought I am who? Abby who? Harry who? Artist who? Abbot who? Needle and who? Harry can you who? Here are you!\"\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\"Knock, knock. Whos there? All you much. None review. Ive? Anribla who? Angron Warria work? Norma Annie pood. Ob the here!\"\n",
      "\n",
      "\"Knock, knock. Whos there? The home who? Hennor, thought Io shown gold mista.\"\n",
      "\n",
      "\"Knock, knock. Whos there? Twanna. Pleaking the owner. Orange little to peach. Whos. Interested. Ive excide. Again. who? Nana. Avenue cold Ketchy. Herting Hunter. \" Knock, by doors its worth orange?\"\n",
      "\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.6202\n",
      "Epoch 3/5\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.5115####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\"Knock, knock. Whos there? Imma. Imma who? Are you a little old perfect who? Abbot who? Orange you going to go on the who? Are you a betwerne of the who?\"\n",
      "\n",
      "\"Knock, knock. Whos there? Kirtch. Impatient cows banana who? Annie body who? Althea who? Dish is a little old lady who? Are you dont know who? Ive a little old lady who? Alex who? Annie body who? Althea little later who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Althe\n",
      "\n",
      "\"Knock, knock. Whos there? A herd. Imma who? Alex who? Orange overflowing out here.\"\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\"Knock, knock. Whos there? A ben. Abby. Iona who? Are you a briefin.\"\n",
      "\n",
      "\"Knock, knock. Whos there? Iona. I had to win the working!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Whos there? Scold who? Are you a little old place on you!\"\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\"Knock, knock. Whos there? ill!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Hey, up to the McDooobook Scown ban expand in red do beneath!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Roach. Banana is a letter who? Your survoring Win black, knock. Whos there? Yes. Needle. The teles being lettuce in the scientists fat? Roach insanu!\"\n",
      "\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.5137\n",
      "Epoch 4/5\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.4383####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\"Knock, knock. Whos there? Alex. Olive who? A banana who? A lettuce old lady who? Abbot you the letter who? Althea who? Althea who? Althea watch old little old lady who? Althea who? Althea want to know you who? You suck you!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Alex. Whos there? Scold who? Althea who? Abbot who? Althea who? Althea who? Annie body who? Althea who? A lettuce old little money for the place?\"\n",
      "\n",
      "\"Knock, knock. Whos there? Abby. A be a who? Abby who? A letter who? Althea who? Althea watch outside who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea like the this weekend on the who? Althea who? Althea who? A lettuce old little up, its cold out here.\"\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\"Knock, knock. Whos there? Annie. Annie who? Arfur knocking!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Annie. A superia who? Althea who? Avenue who who? Nana word who? Arfur knocked on your bless the who?\"\n",
      "\n",
      "\"Knock, knock. Whos there? Avenue. Abby banana who? Althea who? Dozen here who? Two-knowey skin boost who? Althea who? Dish you who? Banana who? Arfur knocked on you!\"\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\"Knock, knock. Whos there? Olive. \"Knock, knock. Whos there? Hoo! Any obher, are?\"\n",
      "\n",
      "\"Knock, knock. Whos thos othe is norma you called out?\"\n",
      "\n",
      "\"Knock, knock, bun is. Whos you cominecy to worth giant less how there?\"\n",
      "\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.4397\n",
      "Epoch 5/5\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3927####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\"Knock, knock. Whos there? Alex. Annie who? Althea who? Althea watch old like there? Adore. A herd who? Iona today who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Althea who? Abbot you dont know who this is. Whos there? Annie. A bell who? Althea who? Althea who? Althea \n",
      "\n",
      "\"Knock, knock. Whos there? Althea. Annie who? Althea who? Dish is who? Orange you going to go on the who?\"\n",
      "\n",
      "\"Knock, knock. Whos there? Annie. A bell who? Iona today who? Ivor you go on the working on the who? Althea who? Althea who? Avenue who? Althea watch old little old little old little old little old little old little old little old little old lady who? Alex-plain who? Althea watch overflowing outsid\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\"Knock, knock. Whos there? A little old lady. A lettuce who? Iona today who? Ivor you let me in through you!\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Knock, knock. Whos there? Cows who? A whos there? Iona good who? Your bell the three doors go to an artice.\"\n",
      "\n",
      "\"Knock, knock. Whos there? Annie. A find out here.\"\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\"Knock, knock. Whos there? Norma\n",
      "\n",
      "\"Knock, knock. Whos there? Let. Les you help!\"\n",
      "\n",
      "\"Knock, knock. Whos there? Etch? Ina ben. Althea.\"\n",
      "\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.3924\n",
      "\"Knock, knock. Whos there? Abort. Alien has over!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file(\n",
    "    file_path=file_name,\n",
    "    new_model=True,\n",
    "    num_epochs=train_cfg['num_epochs'],\n",
    "    gen_epochs=train_cfg['gen_epochs'],\n",
    "    batch_size=1024,\n",
    "    train_size=train_cfg['train_size'],\n",
    "    dropout=train_cfg['dropout'],\n",
    "    validation=train_cfg['validation'],\n",
    "    is_csv=train_cfg['is_csv'],\n",
    "    rnn_layers=model_cfg['rnn_layers'],\n",
    "    rnn_size=model_cfg['rnn_size'],\n",
    "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
    "    max_length=model_cfg['max_length'],\n",
    "    dim_embeddings=100,\n",
    "    word_level=model_cfg['word_level'])\n",
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
